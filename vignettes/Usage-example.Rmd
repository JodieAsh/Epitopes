---
title: "Usage example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Usage example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction
This document illustrates an example of how the `epitopes` package can be used 
to create an organism-specific epitope predictor.

## Initial setup:

The `epitopes` package provides functions to download, extract, consolidate and pre-process epitope data from the [Immune Epitope Database (IEDB)](http://www.iedb.org/), together with protein data (retrieved from NCBI and Uniprot) and taxonomy information for each pathogen (also from NCBI).

This initial part is quite time-consuming, but it 
only needs to be done once, at the start of any project (or possibly once every few months, to get updated versions of the database). Once these are retrieved and saved, they can be loaded using simple `readRDS()` calls.

```{r, eval=FALSE}
# library(epitopes)
# 
# # Download the full IEDB export into a given folder "XYZ"
# epitopes::get_IEDB(save_folder = "XYZ")
# 
# # Extract only the linear B-cell epitopes from the IEDB export and save the 
# # result to folder "ABC"
# epitopes <- epitopes::get_LBCE(data_folder = "XYZ", 
#                                ncpus = parallel::detectCores() - 2,
#                                save_folder = "ABC")
# 
# # Retrieve the relevant proteins and save them into the same folder "ABC"
# proteins <- epitopes::get_proteins(uids = unique(epitopes$protein_id),
#                                    save_folder = "ABC")
# 
# # Retrieve a taxonomy list for all pathogens and save it into the same folder "ABC"
# taxonomy <- epitopes::get_taxonomy(uids = unique(c(epitopes$sourceOrg_id,
#                                                    epitopes$host_id)),
#                                    save_folder = "ABC")

```

## Usage Pipeline

Functions in the _epitopes_ package are designed to work well with _dplyr_ 
pipelines. To go from the initial files to a data structure containing the the 
data splits (training / hold-out, cross-validation folds or any other data 
splitting required) and the desired local and global features, just follow the 
example below:

```{r, eval = FALSE}
library(epitopes)

epitopes <- readRDS("./data/epitopes.rds") # Generated by get_IEDB() -> get_LBCE()
proteins <- readRDS("./data/proteins.rds") # Generated by get_proteins()
taxonomy <- readRDS("./data/taxonomy.rds") # Generated by get_taxonomy()

orgID <- 10376 # Taxonomy ID for the Epstein-Barr virus
ncpus <- parallel::detectCores() - 2

peptides.list <- epitopes %>%
  filter_epitopes(orgIDs        = orgID, # <--- Filter entries by organism ID
                  tax_list      = taxonomy) %>%
  consolidate_data(proteins, 
                   only_exact = FALSE, # <----- Also include 'epitope containing regions'
                   ncpus = ncpus) %>%
  extract_peptides(min_peptide = 8, # <-------- shortest labelled peptide considered (regardles of Class)
                   max_epitope = 25) %>% # <--- longest positively-labelled entry considered
  make_data_splits(proteins     = proteins,
                   target_props = c(.25, .75), # <-- desired split proportions
                   similarity_threshold = .6,  # <-- proteins more similar than this are always placed in the same split.
                   ncpus = ncpus) %>%
  calc_features(
    # local features are calculated for the local windows and added to peptides.list$df
    local.features = c("Entropy","MolWeight", "AAtypes", "Atoms", "AAC", "CTDC", "CTDD", "CTDT", "BLOSUM"), 
    # global features are calculated at the full protein level and added to peptides.list$proteins (needs a data join on df later, before training the models)
    global.features = c("AAC", "DC", "CTDC", "CTDD", "CTDT", "CTriad", "SOCN", "Entropy", "MolWeight", "AAtypes"),
    ncpus = ncpus)
```

The resulting `peptides.list` contains information not only about the results, 
but also the function parameters used at each step:

```{r, eval=FALSE}
> names(peptides.list)
[1] "df"                "peptides"          "filter.attrs"      "consolidate.attrs" "peptide.attrs"    
[6] "proteins"          "splits.attrs"      "feature.attrs"
```

- `df` contains the labelled entries by protein position, plus the local feature columns and the split information
- `proteins` contains the protein data, plus the global feature columns
- `peptides` contains a summary of the labelled peptides in the data
- `filter.attrs`, `consolidate.attrs`, `peptide.attrs` and `feature.attrs` contain information about the parameters used for `filter_epitopes()`, `consolidate_data()`, `extract_peptides()` and `calc_features()`.
- `splits.attrs` contains information about the parameters used for `make_data_splits()`, together with relevant quantities calculated as part of that routine (clusters identified, similarity matrices, cluster allocation to splits, etc.)


For more information please refer to the documentation of the specific functions used above.

## Exporting data

Function `save_peptide_list()` is available to to export the full information from objects of type `peptide.list` (e.g., output of `extract_peptides()`, `make_data_splits()` or `calc_features()`) to a set of CSV files (plus a single RDS file with the clustering structure calculated in `make_data_splits()`) for easier sharing and cross-platform use.
